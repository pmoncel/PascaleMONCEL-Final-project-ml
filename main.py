from src.data_loader import load_data
from src.models.decision_tree import decision_tree
from src.models.gb_optimisation import gb_optimisation
from src.models.gradient_boosting import gradient_boosting
from src.models.random_forest import random_forest
from src.models.regression_logistique import regression_logistique
from src.preprocessing import preprocess_data


def main():
    try:
        data = load_data()
        print("DonnÃ©es originales chargÃ©es :")
        print(data.head())

        # FEATURE ENGINEERING : Activer/DÃ©sactiver
        # Passez feature_engineering=True ou False (dÃ©faut car pas d'amÃ©lioration)
        X_train, X_test, y_train, y_test, preprocessor = preprocess_data(data, feature_engineering=False)

        print("\nDonnÃ©es prÃ©traitÃ©es :")
        print(f"X_train: {X_train.shape}, X_test: {X_test.shape}")
        print(f"y_train: {y_train.shape}, y_test: {y_test.shape}")
        print("\nPrÃ©processeur prÃªt (non encore fit).")
        print("----------------------------------------")
        print("---- MODELE EN ENTRAINEMENT â‰ˆ 40'' -----")

        # ModÃ¨le 1 - RÃ©gression logistique ( â‰ˆ 0.8661)
        # regression_logistique(X_train, X_test, y_train, y_test, preprocessor)

        # ModÃ¨le 2 - Arbre de dÃ©cision basique ( â‰ˆ 0.9196)
        # decision_tree(X_train, X_test, y_train, y_test, preprocessor)

        # ModÃ¨le 3 - ForÃªt alÃ©atoire ( â‰ˆ 0.9028)
        # random_forest(X_train, X_test, y_train, y_test, preprocessor)

        # ModÃ¨le 4 - ðŸ† Gradient Boosting ( â‰ˆ 0.9406 au premier tour sans optimisation)
        # Etant donnÃ©e le rÃ©sultat de ce dernier modÃ¨le,
        # voyons s'il est amÃ©liorable par RandomizedSearchCV.
        # gb_optimisation (X_train, X_test, y_train, y_test, preprocessor)
        # hyperparamÃ¨tres optimaux :
        # {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 253}
        # Avec ces hyperparamÃ¨tres, le rÃ©sultat est : ðŸ†0.9744ðŸ†

        gradient_boosting(X_train, X_test, y_train, y_test, preprocessor)

        conclusion = "-----------------------------"
        conclusion += "\nConclusions: Accuracy = 0.9744"
        conclusion += (
            "\nDÃ©sÃ©quilibre des classes, F1-score sera une mÃ©trique importante"
        )
        conclusion += "\nPrÃ©dictions - low    -> 99%"
        conclusion += "\nPrÃ©dictions - medium -> 96%"
        conclusion += "\nPrÃ©dictions - hight  -> 96%"
        conclusion += "\n-----------------------------"
        print(conclusion)

    except Exception as e:
        print(f"Erreur : {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
